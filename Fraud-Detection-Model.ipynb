{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaacc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Code in Python Jupyter Lab für ein elementares Fraud Detection Modell\n",
    "\n",
    "# VORLESUNG 1:\n",
    "\n",
    "# Importiere Library Pandas in Python\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Lade das CSV File\n",
    "df = pd.read_csv(\"onlinefraud.csv\")\n",
    "\n",
    "# Schreibe die Datenstruktur aus dem DataFrame auf dem Bildschirm\n",
    "print(df)\n",
    "\n",
    "# Schreibe spezifische Elemente und die Datentypen innerhalb von DataFrame\n",
    "print(df.iloc[8])\n",
    "print(df.dtypes)\n",
    "\n",
    "# Schreibe die statistische Kennzahlen\n",
    "df.describe()\n",
    "\n",
    "# VORLESUNG 2:\n",
    "\n",
    "# Selektiere nur die numerischen Werte\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "print(numeric_df)\n",
    "\n",
    "# Berechne die Korrelationen\n",
    "print(numeric_df.corr())\n",
    "\n",
    "# Selektiere nur die nicht-numerischen Werte\n",
    "non_numeric_df = df.select_dtypes(exclude='number')\n",
    "print(non_numeric_df)\n",
    "\n",
    "# VORLESUNG 3:\n",
    "\n",
    "# Innerhalb der Library Sklearn - verwende einen Label Encoder \n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encodiere alle nicht-numerischen Spalten\n",
    "for col in df.select_dtypes(exclude='number').columns:\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Schreibe die Korrelationen der enkodierten (nicht-numerischen) Werte\n",
    "print(df)\n",
    "print(df.corr())\n",
    "\n",
    "# Lade die CSV Daten neu in den Arbeitsspeicher\n",
    "df = pd.read_csv(\"onlinefraud.csv\")\n",
    "print(df)\n",
    "\n",
    "# Projiziere die Daten auf den Unterraum der als Fraud deklarierten Einheiten\n",
    "FindFraudStructures = df.loc[df[\"isFlaggedFraud\"] == 1, [\"nameDest\", \"isFlaggedFraud\", \"amount\"]].copy()\n",
    "print(FindFraudStructures)\n",
    "\n",
    "# Zähle die Anzahl der als Fraud deklarierten Einheiten\n",
    "FindFraudStructures.count()\n",
    "\n",
    "# VORLESUNG 4:\n",
    "\n",
    "# Lege eine Klassifizierung für die als Fraud deklarierten Transaktionen fest\n",
    "FindFraudStructures[\"ClassifyFraud\"] = pd.cut(\n",
    "    df[\"amount\"],\n",
    "    bins=[0, 100.0, 100000.0, 100000000.0],         # Grenzen der Intervalle\n",
    "    labels=[\"no fraud\", \"fraud\", \"extreme fraud\"]  # Namen für die Gruppen\n",
    ")\n",
    "\n",
    "# Gebe die Datenstruktur aus\n",
    "print(FindFraudStructures)\n",
    "\n",
    "# Speichere die als Fraud deklarierten Transaktionen in einem TXT File\n",
    "FindFraudStructures.to_csv(\"FraudPatterns.txt\", sep=\"\\t\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# VORLESUNG 5:\n",
    "\n",
    "# Erzeuge einen beispielhaften Datensatz (Generative Daten) aus einem generativen Modell zur Datenerzeugung\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Reproduzierbarkeit\n",
    "np.random.seed(42)\n",
    "\n",
    "## Anzahl der Samples\n",
    "n_samples = 1000\n",
    "\n",
    "## Zeitliche Dimension\n",
    "steps = np.random.randint(1, 744, size=n_samples)  # ähnlich wie 1–743 im Original\n",
    "\n",
    "## Transaktionstypen\n",
    "types = np.random.choice(['PAYMENT', 'TRANSFER', 'CASH_OUT', 'DEBIT', 'CASH_IN'],\n",
    "                         size=n_samples)\n",
    "\n",
    "## Beträge (positiv, lognormal verteilt -> viele kleine, wenige große)\n",
    "amounts = np.random.lognormal(mean=10, sigma=1, size=n_samples) / 100\n",
    "\n",
    "## Sender-IDs (z. B. Kundenkonten)\n",
    "nameOrig = [\"C\" + str(np.random.randint(100000000, 999999999)) for _ in range(n_samples)]\n",
    "\n",
    "## Ursprüngliches Guthaben (immer >= amount)\n",
    "oldbalanceOrg = amounts + np.random.uniform(0, 1e6, size=n_samples)\n",
    "\n",
    "## Neues Guthaben\n",
    "newbalanceOrg = oldbalanceOrg - amounts\n",
    "newbalanceOrg = np.clip(newbalanceOrg, 0, None)  # keine negativen Salden\n",
    "\n",
    "## Empfänger-IDs (C... für Kunden, M... für Händler)\n",
    "nameDest = []\n",
    "for _ in range(n_samples):\n",
    "    if np.random.rand() < 0.7:  # 70% gehen an Händler\n",
    "        nameDest.append(\"M\" + str(np.random.randint(100000000, 999999999)))\n",
    "    else:\n",
    "        nameDest.append(\"C\" + str(np.random.randint(100000000, 999999999)))\n",
    "\n",
    "## Ziel-Salden (vereinfachtes Modell)\n",
    "oldbalanceDest = np.random.uniform(0, 1e6, size=n_samples)\n",
    "newbalanceDest = oldbalanceDest + amounts\n",
    "\n",
    "## Fraud-Indikator (z. B. 1% Fraud)\n",
    "isFraud = np.random.choice([0, 1], size=n_samples, p=[0.95, 0.05])\n",
    "\n",
    "## Flagged Fraud (z. B. wenn Betrag > 200.000)\n",
    "isFlaggedFraud = (amounts > 200).astype(int)\n",
    "\n",
    "## DataFrame bauen\n",
    "df = pd.DataFrame({\n",
    "    'step': steps,\n",
    "    'type': types,\n",
    "    'amount': np.round(amounts, 2),\n",
    "    'nameOrig': nameOrig,\n",
    "    'oldbalanceOrg': np.round(oldbalanceOrg, 2),\n",
    "    'newbalanceOrig': np.round(newbalanceOrg, 2),\n",
    "    'nameDest': nameDest,\n",
    "    'oldbalanceDest': np.round(oldbalanceDest, 2),\n",
    "    'newbalanceDest': np.round(newbalanceDest, 2),\n",
    "    'isFraud': isFraud,\n",
    "    'isFlaggedFraud': isFlaggedFraud\n",
    "})\n",
    "\n",
    "## CSV speichern\n",
    "df.to_csv(\"Synthetic_Transactions.csv\", index=False)\n",
    "\n",
    "print(\"Synthetic dataset saved as 'Synthetic_Transactions.csv'\")\n",
    "\n",
    "# VORLESUNG 7:\n",
    "\n",
    "# Neues CSV File laden\n",
    "df = pd.read_csv(\"Synthetic_Transactions.csv\")\n",
    "value_count = 0.0\n",
    "\n",
    "# Durch jede Zeile von FindFraudStructures iterieren\n",
    "for i in range(len(FindFraudStructures)):\n",
    "\n",
    "    value = FindFraudStructures[\"nameDest\"].iloc[i]\n",
    "\n",
    "    if value in df[\"nameDest\"].values:\n",
    "    \n",
    "        print(value)\n",
    "    \n",
    "    if value in df[\"nameDest\"].values:\n",
    "    \n",
    "        value_count = value_count + 1\n",
    "\n",
    "print(int(value_count))\n",
    "print(len(df[\"nameDest\"]))\n",
    "\n",
    "# VORLESUNG 8:\n",
    "\n",
    "# Im folgenden wird ein generatives Modell definiert\n",
    "\n",
    "## Importieren die richtigen Libraries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Lade CSV Daten\n",
    "df = pd.read_csv(\"Synthetic_Transactions.csv\")\n",
    "\n",
    "# Kategorische Variablen encoden\n",
    "label_encoders = {}\n",
    "\n",
    "for col in [\"type\", \"nameOrig\", \"nameDest\"]:\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Features und Ziele definieren\n",
    "input_data = df.drop([\"isFraud\", \"isFlaggedFraud\"], axis=1)\n",
    "output_data = df[\"isFraud\"]\n",
    "\n",
    "# Daten normalisieren (SVM mag skalierte Daten)\n",
    "scaler = StandardScaler()\n",
    "input_data_scaled = scaler.fit_transform(input_data)\n",
    "\n",
    "# Train/Test Splitting festlegen\n",
    "input_data_train, input_data_test, output_data_train, output_data_test = train_test_split(\n",
    "    input_data_scaled, output_data, test_size=0.3, random_state=42, stratify=output_data\n",
    ")\n",
    "\n",
    "# SVM Modell definieren (Support Vector Maschine)\n",
    "svm = SVC(kernel=\"rbf\", class_weight=\"balanced\")  # \"balanced\" falls Fraud selten ist\n",
    "svm.fit(input_data_train, output_data_train)\n",
    "\n",
    "# Vorhersagen generieren \n",
    "output_data_pred = svm.predict(input_data_test)\n",
    "\n",
    "# Ergebnisse in einer Konfusionsmatrix speichern\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(output_data_test, output_data_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(output_data_test, output_data_pred))\n",
    "\n",
    "# Spezifische Vorhersage generieren\n",
    "# Eingabedaten (als DataFrame mit den gleichen Spalten wie die Eingabedaten, welche in der Variablen input_data gespeichert sind)\n",
    "\n",
    "new_transaction = pd.DataFrame([{\n",
    "    \"step\": 118,\n",
    "    \"type\": \"PAYMENT\",\n",
    "    \"amount\": 180.00,\n",
    "    \"nameOrig\": \"C613567293\",\n",
    "    \"oldbalanceOrg\": 595905.09,\n",
    "    \"newbalanceOrig\": 595905.09,\n",
    "    \"nameDest\": \"C967937996\",\n",
    "    \"oldbalanceDest\": 105402.96,\n",
    "    \"newbalanceDest\": 115228.23\n",
    "}])\n",
    "\n",
    "# Gleiche LabelEncoder verwenden wie beim Training\n",
    "for col, le in label_encoders.items():\n",
    "    new_transaction[col] = le.transform(new_transaction[col])\n",
    "\n",
    "# Skalieren wie beim Training\n",
    "new_transaction_scaled = scaler.transform(new_transaction)\n",
    "\n",
    "# Vorhersage generieren\n",
    "output_data_pred = svm.predict(new_transaction_scaled)\n",
    "\n",
    "# Vorhersagewert schreiben\n",
    "print(\"Vorhersage (0 = kein Fraud, 1 = Fraud):\", output_data_pred[0])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
